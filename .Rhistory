# 90%CI = 1.65*sd/sqrt(n) or 1.65*se
topCI<-1.96*summary.statistics[1,5] #selecting for row (1st), then column (5th)
bottomCI<-1.96*summary.statistics[2,5] #selecting for row (2nd), then column (5th)
print(topCI)
print(bottomCI)
#Wrangling the Data
Top<- c(3,1,0,5,4,3,6,3,4,7, 3,1,0,5,4,3,6,3,4,7)
Bottom<-c(3,12,3,4,7,8,7,5,15,9, 3,12,3,4,7,8,7,5,15,9)
dataframe<-as.data.frame(cbind(Top, Bottom)) #binds strings together into a data frame
#glimpse(dataframe)
dataframe<-gather(data=dataframe, key=Location, value=Protozoa, Top:Bottom, factor_key=TRUE) # convert to long format (#Top:Bottom = selection of columns)
#calculating statistics for data using functions and the summarize() command
se <- function(x) (sd(x) / sqrt(length(x))) #creating function for standard error
mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
} #creating function for Mode
#summarized statistics by group
summary.statistics <- dataframe %>%
group_by(Location) %>%
summarize(Mean=mean(Protozoa), Standard.Deviation=sd(Protozoa), Variance=var(Protozoa), Standard.Error=se(Protozoa), Median=median(Protozoa), Mode=mode(Protozoa))
print(summary.statistics)
#Constructing a Confidence Interval
# 99%CI = 2.58*sd/sqrt(n) or 2.58*se
# 95%CI = 1.96*sd/sqrt(n) or 1.96*se
# 90%CI = 1.65*sd/sqrt(n) or 1.65*se
topCI<-1.96*summary.statistics[1,5] #selecting for row (1st), then column (5th)
bottomCI<-1.96*summary.statistics[2,5] #selecting for row (2nd), then column (5th)
print(topCI)
print(bottomCI)
1.670998693-0.9037950396
2.427904812- 1.313183748
2.427904812-1.313183748
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(tidyverse)
library(dplyr)
library(ggplot2)
library(here)
library(psych)
library(moments)
library(car)
dataframe <- read_csv(here("Data", "Cancer.csv"))
glimpse(dataframe)
dataframe <- read_csv(here("Data", "Runtimes.csv"))
glimpse(dataframe)
dataframe <- read_csv(here("Data", "Cancer.csv"))
glimpse(dataframe)
dataframe <- gather(dataframe, Treatment, Time, Water:Sportsdrink, factor_key=TRUE)
glimpse(dataframe)
view(dataframe)
dataframe <- read_csv(here("Data", "Cancer.csv"))
glimpse(dataframe)
dataframe <- gather(dataframe, Treatment, Time, Water:Sportsdrink, factor_key=TRUE)
glimpse(dataframe)
ataframe
view(dataframe)
dataframe <- read_csv(here("Data", "Runtimes.csv"))
view(dataframe)
dataframe <- gather(dataframe, Dish, Cellgrowth, Water:Sportsdrink, factor_key=TRUE)
view(dataframe)
dataframe <- read_csv(here("Data", "Cancer.csv"))
glimpse(dataframe)
view(dataframe)
qqp(dataframe$Time, "norm")
qqp(dataframe$Cellgrowth, "norm")
dataframe <- read_csv(here("Data", "Cancer.csv"))
dataframe
qqp(dataframe$CellGrowth, "norm")
shapiro.test(dataframe$Time)
shapiro.test(dataframe$CellGrowth)
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Cancer.csv"))
#view(dataframe)
#check for normality
qqp(dataframe$CellGrowth, "norm") #data appears normal
shapiro.test(dataframe$CellGrowth) # P>0.05 - the data is normal
#conducting a paired t-test since treatments are not indepdent of one another
paired.t.test<-t.test(CellGrowth~Time, paired=TRUE, data=dataframe)
print(paired.t.test)
paired.t.test<-t.test(CellGrowth~Time, paired=TRUE, data=dataframe)
print(paired.t.test)
#clear the environment
rm(list=ls())
se <- function(x) (sd(x) / sqrt(length(x)))
#load data
dataframe <- read_csv(here("Data", "Runtimes.csv"))
dataframe <- gather(dataframe, Treatment, Cellgrowth, Water:Sportsdrink, factor_key=TRUE)
#glimpse(dataframe)
#check for normality prior to plotting
#qqp(dataframe$Time, "norm")
#shapiro.test(dataframe$Time) #If P>0.05, then the data is normal
paired.t.test<-t.test(Time~Treatment, paired=TRUE, data=dataframe)
#clear the environment
rm(list=ls())
se <- function(x) (sd(x) / sqrt(length(x)))
#load data
dataframe <- read_csv(here("Data", "Runtimes.csv"))
dataframe <- gather(dataframe, Treatment, Time, Water:Sportsdrink, factor_key=TRUE)
#glimpse(dataframe)
#check for normality prior to plotting
#qqp(dataframe$Time, "norm")
#shapiro.test(dataframe$Time) #If P>0.05, then the data is normal
paired.t.test<-t.test(Time~Treatment, paired=TRUE, data=dataframe)
print(paired.t.test)
boxplot(CellGrowth~Time, data=dataframe)
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Cancer.csv"))
#view(dataframe)
#check for normality
qqp(dataframe$CellGrowth, "norm") #data appears normal
shapiro.test(dataframe$CellGrowth) # P>0.05 - the data is normal
#conducting a paired t-test since treatments are not indepdent of one another
paired.t.test<-t.test(CellGrowth~Time, paired=TRUE, data=dataframe)
print(paired.t.test)
boxplot(CellGrowth~Time, data=dataframe)
cv <- function(x) (sd(x)/mean(x))
dataframe <- read_csv(here("Data", "Temps.csv"))
view(dataframe)
dataframe <- dataframe %>%
mutate(Person=as.factor(Person))
dataframe
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Temps.csv"))
#view(dataframe)
dataframe <- dataframe %>%
mutate(Person=as.factor(Person))
#calculating statistics for data using functions and the summarize() command
cv <- function(x) (sd(x)/mean(x))# creating function for cv
se <- function(x) (sd(x) / sqrt(length(x))) #creating function for standard error
#summarized statistics by group
summary.statistics <- dataframe %>%
group_by(Person) %>%
summarize(Mean=mean(Temperature), Median=median(Temperature), Standard.Deviation=sd(Temperature),  Standard.Error=se(Temperature),  Coefficient.Of.Variation=cv(Temperature))
print(summary.statistics)
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Temps.csv"))
#view(dataframe)
#calculating statistics for data using functions and the summarize() command
cv <- function(x) (sd(x)/mean(x))# creating function for cv
se <- function(x) (sd(x) / sqrt(length(x))) #creating function for standard error
#summarized statistics by group
summary.statistics <- dataframe %>%
summarize(Mean=mean(Temperature), Median=median(Temperature), Standard.Deviation=sd(Temperature),  Standard.Error=se(Temperature),  Coefficient.Of.Variation=cv(Temperature))
print(summary.statistics)
#bootstrapping means
bootstrapped.mean<-replicate(1000, {
samples<-sample(dataframe$Temperature, replace=TRUE);
mean(samples)  }) #take the mean of the subsample
#this output provides 1000 different estimates of the mean, based on 1000 random samples
sortedboots<-sort(bootstrapped.mean) #sorting means
mean <- mean(bootstrapped.mean)
print(mean)
#constructing the 95% confidence intervals using (25th and 975th place)
lowCI<-sortedboots[25]
highCI<-sortedboots[975]
upperCI<-highCI - mean(bootstrapped.mean)
lowerCI<-mean(bootstrapped.mean) - lowCI
confidence.interval <-c(lowerCI, upperCI)
print(confidence.interval)
#histogram of bootstrapped means
hist(sortedboots, col="lightcyan", main="Bootstrapped Histogram of Agaricia agaricites Weights", xlab="Weight", ylab ="Frequency")
abline(v=lowCI, col="darkcyan") #adding vertical lines for the low and high CIs
abline(v=highCI, col="darkcyan")
#bootstrapping means
bootstrapped.mean<-replicate(1000, {
samples<-sample(dataframe$Temperature, replace=TRUE);
mean(samples)  }) #take the mean of the subsample
#this output provides 1000 different estimates of the mean, based on 1000 random samples
sortedboots<-sort(bootstrapped.mean) #sorting means
mean <- mean(bootstrapped.mean)
print(mean)
#constructing the 95% confidence intervals using (25th and 975th place)
lowCI<-sortedboots[25]
highCI<-sortedboots[975]
upperCI<-highCI - mean(bootstrapped.mean)
lowerCI<-mean(bootstrapped.mean) - lowCI
confidence.interval <-c(lowerCI, upperCI)
print(confidence.interval)
#histogram of bootstrapped means
hist(sortedboots, col="lightcyan", density=25, angle=60, main="Bootstrapped Histogram of CSUN Student's Temperature", xlab="Temperature (degrees C)", ylab ="Frequency")
abline(v=lowCI, col="darkcyan") #adding vertical lines for the low and high CIs
abline(v=highCI, col="darkcyan")
#bootstrapping means
bootstrapped.mean<-replicate(1000, {
samples<-sample(dataframe$Temperature, replace=TRUE);
mean(samples)  }) #take the mean of the subsample
#this output provides 1000 different estimates of the mean, based on 1000 random samples
sortedboots<-sort(bootstrapped.mean) #sorting means
mean <- mean(bootstrapped.mean)
print(mean)
#constructing the 95% confidence intervals using (25th and 975th place)
lowCI<-sortedboots[25]
highCI<-sortedboots[975]
upperCI<-highCI - mean(bootstrapped.mean)
lowerCI<-mean(bootstrapped.mean) - lowCI
confidence.interval <-c(lowerCI, upperCI)
print(confidence.interval)
#histogram of bootstrapped means
hist(sortedboots, col="darkcyan", density=25, angle=60, main="Bootstrapped Histogram of CSUN Student's Temperature", xlab="Temperature (degrees C)", ylab ="Frequency")
abline(v=lowCI, col="darkcyan") #adding vertical lines for the low and high CIs
abline(v=highCI, col="darkcyan")
qqp(dataframe$Temperature, "norm")
shapiro.test(dataframe$Temperature)
#one sample t-test
one.sample.t.test<-t.test(dataframe$Temperature, mu=98.6, na.rm=TRUE) #null hypothesis set to 98.6 degrees 4
print(one.sample.t.test)
#calculating statistics for data using functions and the summarize() command
summary.statistics <- dataframe %>%
group_by(Site) %>%
summarize(Mean=mean(Count), Standard.Deviation=sd(Count), Standard.Error =se(Count),
Variance=var(Count))
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Sargassum.csv"))
dataframe
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Sargassum.csv"))
#view(dataframe)
se <- function(x) (sd(x) / sqrt(length(x))) #standard error function
#calculating statistics for data using functions and the summarize() command
summary.statistics <- dataframe %>%
group_by(treatment) %>%
summarize(Mean=mean(biomass), Standard.Deviation=sd(biomass), Standard.Error =se(biomass), Variance=var(biomass))
print(summary.statistics)
#variances are substantially different therefore we would prefer to run a Welch's t-test
view(summary.statistics)
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Sargassum.csv"))
#view(dataframe)
se <- function(x) (sd(x) / sqrt(length(x))) #standard error function
#calculating statistics for data and determining which two sided test to use
summary.statistics <- dataframe %>%
group_by(treatment) %>%
summarize(Mean=mean(biomass), Standard.Deviation=sd(biomass), Standard.Error =se(biomass), Variance=var(biomass))
# view(summary.statistics)
#variances are substantially different therefore we would prefer to run a Welch's t-test
unequal.variance.t.test<-t.test(biomass~site, var.equal=FALSE, data=dataframe)
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Sargassum.csv"))
#view(dataframe)
se <- function(x) (sd(x) / sqrt(length(x))) #standard error function
#calculating statistics for data and determining which two sided test to use
summary.statistics <- dataframe %>%
group_by(treatment) %>%
summarize(Mean=mean(biomass), Standard.Deviation=sd(biomass), Standard.Error =se(biomass), Variance=var(biomass))
# view(summary.statistics)
#variances are substantially different therefore we would prefer to run a Welch's t-test
unequal.variance.t.test<-t.test(biomass~treatment, var.equal=FALSE, data=dataframe)
print(unequal.variance.t.test)
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Sargassum.csv"))
#view(dataframe)
se <- function(x) (sd(x) / sqrt(length(x))) #standard error function
#calculating statistics for data and determining which two sided test to use
summary.statistics <- dataframe %>%
group_by(treatment) %>%
summarize(Mean=mean(biomass), Standard.Deviation=sd(biomass), Standard.Error =se(biomass), Variance=var(biomass))
# view(summary.statistics)
#variances are substantially different therefore we would prefer to run a Welch's t-test
unequal.variance.t.test<-t.test(biomass~treatment, var.equal=FALSE, data=dataframe)
print(unequal.variance.t.test)
#gather summary statistic data necessary to create a boxplot (mean and standard error)
graphdata <-summary.statistics %>%
select(treatment, Mean, Standard.Error)
#glimpse(graphdata)
#graphing a boxplot using ggplot
ggplot(graphdata) +
geom_bar( aes(x=treatment, y=Mean, fill=treatment), stat="identity", alpha=0.85) +
geom_errorbar( aes(x=treatment, ymin=Mean-Standard.Error, ymax=Mean+Standard.Error), width=0.5, colour="black",
alpha=0.95, size=1)+
theme(legend.position = "right", legend.title=element_text(size=20),
legend.text=element_text(size=14))+
theme_minimal() +
labs(x="Treatment", y="Biomass (g/m2)", fill="treatment", title = "Difference of S. horneri Biomass (g/m2)\n in Shaded versus Unshaded Plots", caption =
"Figure 1. Mean (+/-SE) of biomass g/m^2 at unshaded versus shaded 1m^2 plot. \n The topography was more complex at Site 2 than at Site 1.")
dataframe <- read_csv(here("Data", "Cancer.csv"))
dataframe
#clear the environment
rm(list=ls())
#load data
dataframe <- read_csv(here("Data", "Cancer.csv"))
#view(dataframe)
#check for normality
qqp(dataframe$CellGrowth, "norm") #data appears normal
shapiro.test(dataframe$CellGrowth) # P>0.05 - the data is normal
#conducting a paired t-test since treatments are not indepdent of one another
paired.t.test<-t.test(CellGrowth~Time, paired=TRUE, data=dataframe)
print(paired.t.test)
boxplot(CellGrowth~Time, data=dataframe)
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(modelr)
require(kableExtra)
require(plotly)
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(modelr)
require(kableExtra)
require(plotly)
iris=iris
#first plot the variables to see how they are related.
scatterplot = ggplot(data = iris, aes(x = Sepal.Length ,
y = Sepal.Width,
col = Species))+
geom_point()+
cowplot::theme_cowplot()+
scale_x_continuous(breaks = seq(0,7,1.5))+
labs(x = "Sepal length (cm)",
y = "Sepal width (cm)")
plotly::ggplotly(fig1) #%>%style()%>%layout(legend = list(x = 0.8, y = 0.95))
#first plot the variables to see how they are related.
scatterplot = ggplot(data = iris, aes(x = Sepal.Length ,
y = Sepal.Width,
col = Species))+
geom_point()+
cowplot::theme_cowplot()+
scale_x_continuous(breaks = seq(0,7,1.5))+
labs(x = "Sepal length (cm)",
y = "Sepal width (cm)")
plotly::ggplotly(scatterplot) #%>%style()%>%layout(legend = list(x = 0.8, y = 0.95))
#residuals of the model
iris = iris%>%
add_residuals(petal.mod)
---
title: "Linear_Model_Codes"
author: "Robert Dellinger"
date: "10/1/2022"
output: html_document
---
## Introduction
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(modelr)
require(kableExtra)
require(plotly)
```
```{r}
iris=iris
```
```{r}
#first plot the variables to see how they are related.
scatterplot = ggplot(data = iris, aes(x = Sepal.Length ,
y = Sepal.Width,
col = Species))+
geom_point()+
cowplot::theme_cowplot()+
scale_x_continuous(breaks = seq(0,7,1.5))+
labs(x = "Sepal length (cm)",
y = "Sepal width (cm)")
plotly::ggplotly(scatterplot) #%>%style()%>%layout(legend = list(x = 0.8, y = 0.95))
```
```{r}
scatterplot.2 = ggplot(data = iris, aes(x = Petal.Length ,
y = Petal.Width,
col = Species))+
geom_point(size = 2)+
cowplot::theme_cowplot()+
scale_x_continuous(breaks = seq(0,7,1.5))+
labs(x = "Petal length (cm)",
y = "Petal width (cm)")
plotly::ggplotly(fig2) #%>%style()%>%layout(legend = list(x = 0.1, y = 0.95))
```
```{r}
#creating a linear model
petal.mod = lm(Petal.Width~Petal.Length, data = iris)
## check coefficients
coef(petal.mod)
```
```{r}
#generates evenly-spaced grid of values that covers the region where our data lies.
grid = iris %>%
data_grid(Petal.Length)
```
```{r}
# modelr’s function add_predictions() adds the predictions from the model to a new column
grid  = grid%>%
add_predictions(petal.mod)
```
```{r}
#plot predictions
fig3 = ggplot(data = iris, aes(x = Petal.Length))+
geom_point(aes(y = Petal.Width))+
geom_line(data = grid, aes(y = pred), col = 2, size = 1)+
cowplot::theme_cowplot()+
scale_x_continuous(breaks = seq(0,7,1.5))+
labs(x = "Petal length (cm)",
y = "Petal width (cm)")
plotly::ggplotly(fig3)
```
```{r}
iris = iris%>%
add_residuals(petal.mod)
iris%>%as.tibble()%>%select(5,1:4,6)%>%sample_n(12)%>%kable("html", digits = 2, align = "c", caption = "The residual values in the dataset", col.names = c("Species", "Length", "Width", "Length", "Width", "Residual"))%>%
add_header_above(c("","Sepal" = 2, "Petal" = 2, ""))%>%
add_header_above(c("", "Flower Measurement (cm)" = 4, ""))%>%
column_spec(1:6, width = "8cm", color = "black", bold = FALSE)
```
```{r}
fig4 = ggplot(data = iris, aes(x = resid))+
geom_freqpoly(binwidth = 0.5)+
cowplot::theme_cowplot() +
labs(x = "Model residuals",y = "Frequencies")
plotly::ggplotly(fig4)
```
```{r}
ggplot(data = iris)+
# geom_ref_line(h = 0, colour = 2) +
geom_point(aes(x = Petal.Length, y = resid))+
geom_hline(yintercept = 0, linetype = 2)+
scale_x_continuous(breaks = seq(0,7,1.5))+
cowplot::theme_cowplot() +
labs(x = "Petal length (cm)",
y = "Residuals")
```
#power modelss/model residuals
```{r}
#residuals of the model
iris = iris%>%
add_residuals(petal.mod)
iris%>%as.tibble()%>%select(5,1:4,6)%>%sample_n(12)%>%kable("html", digits = 2, align = "c", caption = "The residual values in the dataset", col.names = c("Species", "Length", "Width", "Length", "Width", "Residual"))%>%
add_header_above(c("","Sepal" = 2, "Petal" = 2, ""))%>%
add_header_above(c("", "Flower Measurement (cm)" = 4, ""))%>%
column_spec(1:6, width = "8cm", color = "black", bold = FALSE)
```
#plot predictions
fig3 = ggplot(data = iris, aes(x = Petal.Length))+
geom_point(aes(y = Petal.Width))+
geom_line(data = grid, aes(y = pred), col = 2, size = 1)+
cowplot::theme_cowplot()+
scale_x_continuous(breaks = seq(0,7,1.5))+
labs(x = "Petal length (cm)",
y = "Petal width (cm)")
plotly::ggplotly(fig3)
iris = iris%>%
add_residuals(petal.mod)
iris%>%as.tibble()%>%select(5,1:4,6)%>%sample_n(12)%>%kable("html", digits = 2, align = "c", caption = "The residual values in the dataset", col.names = c("Species", "Length", "Width", "Length", "Width", "Residual"))%>%
add_header_above(c("","Sepal" = 2, "Petal" = 2, ""))%>%
add_header_above(c("", "Flower Measurement (cm)" = 4, ""))%>%
column_spec(1:6, width = "8cm", color = "black", bold = FALSE)
fig4 = ggplot(data = iris, aes(x = resid))+
geom_freqpoly(binwidth = 0.5)+
cowplot::theme_cowplot() +
labs(x = "Model residuals",y = "Frequencies")
plotly::ggplotly(fig4)
ggplot(data = iris)+
# geom_ref_line(h = 0, colour = 2) +
geom_point(aes(x = Petal.Length, y = resid))+
geom_hline(yintercept = 0, linetype = 2)+
scale_x_continuous(breaks = seq(0,7,1.5))+
cowplot::theme_cowplot() +
labs(x = "Petal length (cm)",
y = "Residuals")
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(oce)
require(highcharter)
require(lubridate)
setwd("e:/Data Manipulation/kuguru/extracted/")
knitr::opts_chunk$set(echo = TRUE)
## load the package needed for the routine
# library(DT)
library(tidyverse)
library(lubridate)
library(spData)
library(sf)
library(oce)
library(insol)
install.packages("insol")
knitr::opts_chunk$set(echo = TRUE)
## load the package needed for the routine
# library(DT)
library(tidyverse)
library(lubridate)
library(spData)
library(sf)
library(oce)
library(insol)
library(xtractomatic)
# library(pals)
##  Map the Pemba channel with ggplot2, sf and ggsn packages
ggplot()+geom_sf(data = tz.ke, fill = "ivory", col = 1)+
coord_sf(xlim = c(38.5, 40), ylim = c(-6,-4))+
theme_bw()+
theme(panel.background = element_rect(colour = 1, fill = "lightblue"),
panel.grid = element_line(colour = NA),
axis.text = element_text(colour = 1, size = 10))+
scale_x_continuous(breaks = seq(38.5, 40, length.out = 4)%>%round(digits = 1))+
scale_y_continuous(breaks = seq(-5.8, -4.1,length.out = 5)%>%round(digits = 1))+
labs(x = NULL, y = NULL)+
geom_text(aes(x = 39.36, y = -5.2, label = "Pemba\nChannel"), col = "black")+
ggsn::scalebar(location = "bottomright", x.min = 38.5,
x.max = 39.95, y.min = -6, y.max = -4, dist = 25, dd2km = T,
model = "WGS84",st.dist = 0.02, st.size = 4)
